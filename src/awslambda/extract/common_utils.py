from collections import defaultdict
from typing import Dict, List, Optional
from datetime import datetime
import traceback
import json
import re
import requests

import psycopg2
import psycopg2.extras
import pyarrow as pa
import pyarrow.parquet as pq
import boto3
import smart_open
import openai

from settings import (
    DB_HOST,
    DB_NAME,
    DB_USER,
    DB_PASSWORD,
    DB_PORT,
    VIEW_THRESHOLD,
    OPENAI_API_KEY,
    S3_BUCKET,
)

json_match_ptrn = re.compile(r'\{.*\}')
# ì „ì—­ ë³€ìˆ˜ë¡œ connection ê´€ë¦¬
db_conn = None

def get_db_connection():
    global db_conn
    
    # ê¸°ì¡´ ì—°ê²°ì´ ìˆê³  ìœ íš¨í•œì§€ í™•ì¸
    if db_conn is not None:
        try:
            # ê°„ë‹¨í•œ ì¿¼ë¦¬ë¡œ ì—°ê²° ìƒíƒœ í™•ì¸
            with db_conn.cursor() as cur:
                cur.execute('SELECT 1')
            return db_conn
        except Exception:
            # ì—°ê²°ì´ ëŠì–´ì¡Œë‹¤ë©´ Noneìœ¼ë¡œ ì„¤ì •
            db_conn = None
    
    # ìƒˆë¡œìš´ ì—°ê²° ìƒì„±
    try:
        if db_conn is None:
            db_conn = psycopg2.connect(
                host=DB_HOST,
                database=DB_NAME,
                user=DB_USER,
                password=DB_PASSWORD,
                port=DB_PORT,
                cursor_factory=psycopg2.extras.RealDictCursor,  # ê¸°ë³¸ cursor factory ì„¤ì •
                # Timeout ì„¤ì • ì¶”ê°€
                connect_timeout=5,        # ì—°ê²° ì‹œë„ timeout (ì´ˆ)
                keepalives=1,            # TCP keepalive í™œì„±í™”
                keepalives_idle=1800,      # TCP keepalive idle time (ì´ˆ)
                keepalives_interval=10,   # TCP keepalive interval (ì´ˆ)
                keepalives_count=3       # TCP keepalive retry count            
            )
            db_conn.autocommit = True  # í•„ìš”ì— ë”°ë¼ ì„¤ì •
    except Exception as e:
        print(f"DB ì—°ê²° ì—ëŸ¬: {e}")
        return None

    return db_conn

# ì „ì—­ ë³€ìˆ˜ë¡œ s3_client ê´€ë¦¬
s3_client = None

def get_s3_client():
    global s3_client

    if s3_client is not None:
        return s3_client

    try:
        s3_client = boto3.client('s3')
    except Exception as e:
        print(f"S3 í´ë¼ì´ì–¸íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
        return None

    return s3_client

def get_search_keywords(
        conn,
        keyword_set_name: str,
    ) -> Optional[List[str]]:
    """
    ì´í›„ì— airflow DAGì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ í‚¤ì›Œë“œë“¤ì„ í•¨ìˆ˜ë¡œ ë¶„ë¦¬í•©ë‹ˆë‹¤.

    ë³‘ë ¬ search ì‘ì—…ì„ ìœ„í•´ í‚¤ì›Œë“œ ì„¸íŠ¸ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
    Args:
        conn: PostgreSQL ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ê°ì²´
        keyword_set_name: í‚¤ì›Œë“œ ì„¸íŠ¸ ì´ë¦„
    
    Returns:
        í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸
    """
    with conn.cursor() as cursor:
        sql = f"""
        SELECT 
            keywords
        FROM 
            keyword_set
        WHERE
            name = '{keyword_set_name}'            
        """
        cursor.execute(sql)
        result = cursor.fetchone()
        if result is None:
            return None
        return result['keywords']
        

def upsert_post_tracking_data(
        conn,
        table_name, 
        payload: Dict
        ) -> Optional[bool]:
    """
    í•œ í¬ìŠ¤íŒ…ì„ search ë‹¨ê³„ì—ì„œ íŒŒì‹±í•  ë•Œ ë§ˆë‹¤ ë¶ˆëŸ¬ì™€ì•¼ í•©ë‹ˆë‹¤.

    1. ì‹¤íŒ¨ í˜¹ì€ ì°¨ë‹¨ëœ ê²½ìš°: url, status, checked_at í•„ë“œê°€ í•„ìš”í•©ë‹ˆë‹¤.
    2. ìƒˆë¡œìš´ ê²ƒ ë“¤ì–´ì˜¬ ë•Œ: ëª¨ë“  payload í•„ë“œê°€ í•„ìš”í•©ë‹ˆë‹¤.
    2. ê¸°ì¡´ ê²ƒ ì—…ë°ì´íŠ¸: url, status, comment_count, view, created_at, checked_at, keyword í•„ë“œê°€ í•„ìš”í•©ë‹ˆë‹¤.
    
    payload: {
        url: str,
        post_id: str,
        status: str (CHANGED, UNCHANGED, FAILED, BANNED) (ì‹¤íŒ¨ í˜¹ì€ ì°¨ë‹¨ëœ ê²½ìš° í•„ìš”)
        comment_count: int,
        view: int,
        created_at: datetime,
        checked_at: datetime, ì‹¤íŒ¨ í˜¹ì€ ì°¨ë‹¨ëœ ê²½ìš°ì—ë„ í•„ìš”.
        keyword: str,
    }
    
    return None: ì‹¤íŒ¨, True: ì„±ê³µ
    """
    try:
        assert isinstance(payload['url'], str), "urlì€ ë¬¸ìì—´ì´ì–´ì•¼ í•©ë‹ˆë‹¤."
        assert isinstance(payload['checked_at'], datetime), "checked_atì€ datetime ê°ì²´ì—¬ì•¼ í•©ë‹ˆë‹¤."
        url = payload.get('url')
        with conn.cursor() as cursor:
            sql = f"SELECT * FROM {table_name} WHERE url = %s"
            cursor.execute(
                sql,
                (url,)
                )
            
            result = cursor.fetchone()

            if result is None:
                print(f"[INFO] ìƒˆë¡œìš´ ë°ì´í„°: {url}")
                assert isinstance(payload['post_id'], str), "post_idëŠ” ë¬¸ìì—´ì´ì—¬ì•¼ í•©ë‹ˆë‹¤."
                assert isinstance(payload['status'], str), "statusëŠ” ë¬¸ìì—´ì´ì–´ì•¼ í•©ë‹ˆë‹¤."
                assert isinstance(payload['comment_count'], int), "comment_countëŠ” ì •ìˆ˜ì—¬ì•¼ í•©ë‹ˆë‹¤."
                assert isinstance(payload['view'], int), "viewëŠ” ì •ìˆ˜ì—¬ì•¼ í•©ë‹ˆë‹¤."
                assert isinstance(payload['created_at'], datetime), "created_atì€ datetime ê°ì²´ì—¬ì•¼ í•©ë‹ˆë‹¤."
                assert isinstance(payload['keyword'], str), "keywordì€ ë¬¸ìì—´ì´ì–´ì•¼ í•©ë‹ˆë‹¤."
                sql = f"""
                INSERT INTO {table_name} (
                    url,
                    post_id,
                    status,
                    comment_count,
                    view,
                    created_at,
                    checked_at,
                    keywords
                ) VALUES (
                    %s, %s, %s, %s, %s, %s, %s, ARRAY[%s]::TEXT[]
                )
                """
                cursor.execute(
                    sql,
                    (
                        url,
                        payload['post_id'],
                        payload['status'],
                        payload['comment_count'],
                        payload['view'],
                        payload['created_at'],
                        payload['checked_at'],
                        payload['keyword'],
                    )
                )
            else:                
                assert isinstance(payload['status'], str), "statusëŠ” ë¬¸ìì—´ì´ì–´ì•¼ í•©ë‹ˆë‹¤."
                unstable_status = payload['status'] in ["FAILED", "BANNED"]
                if unstable_status:
                    print(f"[WARN] í¬ë¡¤ë§ ë¬¸ì œ ë°œìƒ / ìƒíƒœ ì—…ë°ì´íŠ¸ / ê¸°ì¡´ ë°ì´í„°: {url}")
                    if payload['status'] == "FAILED":                        
                        update_status_failed(conn, table_name, url, payload['checked_at'])
                    elif payload['status'] == "BANNED":
                        update_status_banned(conn, table_name, url, payload['checked_at'])
                    return True
                
                assert isinstance(payload['comment_count'], int), "comment_countëŠ” ì •ìˆ˜ì—¬ì•¼ í•©ë‹ˆë‹¤."
                assert isinstance(payload['view'], int), "viewëŠ” ì •ìˆ˜ì—¬ì•¼ í•©ë‹ˆë‹¤."
                assert isinstance(payload['keyword'], str), "keywordì€ ë¬¸ìì—´ì´ì–´ì•¼ í•©ë‹ˆë‹¤."
                has_valuable_change = (
                    result['view'] - payload['view'] > VIEW_THRESHOLD
                    or result['comment_count'] > payload['comment_count']
                )
                new_keyword_event = payload['keyword'] != "" and payload['keyword'] not in result['keywords']
                if has_valuable_change or new_keyword_event:
                    print(f"[INFO] ì—…ë°ì´íŠ¸ ì‹œí–‰ / ê¸°ì¡´ ë°ì´í„°: {url}")
                    sql = f"""
                    UPDATE {table_name}
                    SET
                        status = %s,
                        comment_count = %s,
                        view = %s,
                        created_at = %s,
                        checked_at = %s,
                        keywords = CASE 
                            WHEN %s = ANY(keywords) THEN keywords
                            ELSE array_append(keywords, %s) 
                        END
                    WHERE url = %s
                    """
                    cursor.execute(
                        sql,
                        (
                            payload['status'],
                            payload['comment_count'],
                            payload['view'],
                            payload['created_at'],
                            payload['checked_at'],
                            payload['keyword'],
                            payload['keyword'],
                            url,
                        )
                    )
                    conn.commit()
                    return True                
                
                print(f"[INFO] ì—…ë°ì´íŠ¸ ë¶ˆí•„ìš” / ê¸°ì¡´ ë°ì´í„°: {url}")
            
            return True
    except Exception as e:
        print(f"[ERROR] DB ì—…ë°ì´íŠ¸ ì—ëŸ¬: {e}")
        traceback.print_exc()
        return None

def get_details_to_parse(
        conn,
        table_name,
        ) -> Optional[List[Dict]]:
    """
    detail ë‹¨ê³„ì—ì„œ ì²˜ë¦¬í•  urlë“¤ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
    """
    try:
        with conn.cursor() as cursor:
            sql = f"""
            SELECT 
                * 
            FROM 
                {table_name} 
            WHERE status != 'UNCHANGED'
            """
            cursor.execute(sql)
            
            result = cursor.fetchall()
            return result
    except Exception as e:
        print(f"[ERROR] DB ì¡°íšŒ ì—ëŸ¬: {e}")
        return None

def update_search_status(
       conn,
       table_name: str,
       url: str,
       checked_at: Optional[datetime],
       status: Optional[str] = None,
       _prevent_direct_status: str = None  # ì§ì ‘ status íŒŒë¼ë¯¸í„°ë¥¼ ë°›ì§€ ëª»í•˜ê²Œ í•˜ëŠ” íŒŒë¼ë¯¸í„°
    ) -> Optional[bool]:
    """DB ë ˆì½”ë“œì˜ ìƒíƒœë¥¼ ì—…ë°ì´íŠ¸í•˜ëŠ” ë‚´ë¶€ í•¨ìˆ˜ì…ë‹ˆë‹¤. ì§ì ‘ í˜¸ì¶œí•˜ì§€ ë§ˆì„¸ìš”.
    ëŒ€ì‹  update_status_failed(), update_status_banned() ë“±ì˜ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.

    Args:
        conn: PostgreSQL ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ê°ì²´
        table_name: ì—…ë°ì´íŠ¸í•  í…Œì´ë¸” ì´ë¦„
        url: ì—…ë°ì´íŠ¸í•  ë ˆì½”ë“œì˜ URL
        checked_at: í™•ì¸ì¼ì
        status: ì—…ë°ì´íŠ¸í•  ìƒíƒœ

    Returns:
        ì„±ê³µ ì‹œ True, ì‹¤íŒ¨ ì‹œ None
    """
    if _prevent_direct_status is None:
        raise ValueError("ì´ í•¨ìˆ˜ëŠ” ì§ì ‘ í˜¸ì¶œí•˜ì§€ ë§ˆì„¸ìš”. ëŒ€ì‹  update_status_failed() ë“±ì„ ì‚¬ìš©í•˜ì„¸ìš”.")
       
    with conn.cursor() as cursor:  # cursor() ë©”ì„œë“œë¡œ ìˆ˜ì •
        try:
            if checked_at is None:
                    sql = f"""
                    UPDATE {table_name}
                    SET
                        status = %s
                    WHERE url = %s
                    """
                    cursor.execute(
                        sql,
                        (
                            status,
                            url
                        )
                    )
            else:
                    sql = f"""
                    UPDATE {table_name}
                    SET
                        status = %s
                        checked_at = %s
                    WHERE url = %s
                    """
                    cursor.execute(
                        sql,
                        (
                            status,
                            checked_at,
                            url
                        )
                    )
            conn.commit()
            return True
        except Exception as e:
            print(f"[ERROR] DB status, checked_at ì—ëŸ¬ / í…Œì´ë¸” ì´ë¦„: {table_name}, status: {status}, checked_at: {checked_at} / ì—ëŸ¬ ë‚´ìš©: {e}")
            return None

def update_status_failed(
        conn,
        table_name: str,
        url: str,
        checked_at: Optional[datetime] = None
        ) -> Optional[bool]:
    """
    detail ë‹¨ê³„ì—ì„œ ì‹¤íŒ¨í•œ urlë“¤ì„ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
    URLì˜ ìƒíƒœë¥¼ FAILEDë¡œ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.

    Args:
       conn: PostgreSQL ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ê°ì²´
       table_name: ì—…ë°ì´íŠ¸í•  í…Œì´ë¸” ì´ë¦„
       url: ì—…ë°ì´íŠ¸í•  ë ˆì½”ë“œì˜ URL

    Returns:
       ì„±ê³µ ì‹œ True, ì‹¤íŒ¨ ì‹œ None
    """
    return update_search_status(conn, table_name, url, checked_at, status="FAILED", _prevent_direct_status="used")

def update_status_banned(
        conn,
        table_name: str,
        url: str,
        checked_at: Optional[datetime] = None
        ) -> Optional[bool]:
    """
    detail ë‹¨ê³„ì—ì„œ ì°¨ë‹¨ëœ urlë“¤ì„ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
    URLì˜ ìƒíƒœë¥¼ BANNEDë¡œ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.

    Args:
       conn: PostgreSQL ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ê°ì²´
       table_name: ì—…ë°ì´íŠ¸í•  í…Œì´ë¸” ì´ë¦„
       url: ì—…ë°ì´íŠ¸í•  ë ˆì½”ë“œì˜ URL

    Returns:
       ì„±ê³µ ì‹œ True, ì‹¤íŒ¨ ì‹œ None
    """
    return update_search_status(conn, table_name, url, checked_at, status="BANNED", _prevent_direct_status="used")

def update_status_unchanged(
        conn,
        table_name: str,
        url:str,
        checked_at: Optional[datetime] = None
        ) -> Optional[bool]:
    """
    detail ë‹¨ê³„ì—ì„œ ì™„ë£Œëœ urlë“¤ì„ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
    URLì˜ ìƒíƒœë¥¼ UNCHANGEDë¡œ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.

    Args:
       conn: PostgreSQL ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ê°ì²´
       table_name: ì—…ë°ì´íŠ¸í•  í…Œì´ë¸” ì´ë¦„
       url: ì—…ë°ì´íŠ¸í•  ë ˆì½”ë“œì˜ URL

    Returns:
       ì„±ê³µ ì‹œ True, ì‹¤íŒ¨ ì‹œ None
    """
    return update_search_status(conn, table_name, url, checked_at, status="UNCHANGED", _prevent_direct_status="used")

def update_status_changed(
        conn,
        table_name: str,
        url: str,
        checked_at: Optional[datetime] = None
        ) -> Optional[bool]:
    """
    detail ë‹¨ê³„ì—ì„œ ë³€ê²½ëœ urlë“¤ì„ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
    URLì˜ ìƒíƒœë¥¼ CHANGEDë¡œ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.

    Args:
       conn: PostgreSQL ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ê°ì²´
       table_name: ì—…ë°ì´íŠ¸í•  í…Œì´ë¸” ì´ë¦„
       url: ì—…ë°ì´íŠ¸í•  ë ˆì½”ë“œì˜ URL

    Returns:
       ì„±ê³µ ì‹œ True, ì‹¤íŒ¨ ì‹œ None
    """
    return update_search_status(conn, table_name, url, checked_at, status="CHANGED", _prevent_direct_status="used")

def update_changed_stats(
        conn,
        table_name: str,
        url: str,
        comment_count: int,
        view: int,
        created_at: datetime,
    ) -> Optional[bool]:
    """
    detailì—ì„œ ë³€í™”ëœ í¬ìŠ¤íŠ¸ì˜ ì •ë³´ë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
    UNCHANGEDë¡œ ë³€ê²½ë„ ì§„í–‰í•©ë‹ˆë‹¤.
    Args:
       conn: PostgreSQL ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ê°ì²´
       table_name: ì—…ë°ì´íŠ¸í•  í…Œì´ë¸” ì´ë¦„
       url: ì—…ë°ì´íŠ¸í•  ë ˆì½”ë“œì˜ URL
       comment_count: ëŒ“ê¸€ ìˆ˜
       view: ì¡°íšŒìˆ˜
       created_at: ì‘ì„±ì‹œê°„
       checked_at: í™•ì¸ì¼ì
    """
    with conn.cursor() as cursor:
        try:
            sql = f"""
            UPDATE {table_name}
            SET
                comment_count = %s,
                view = %s,
                created_at = %s,
                status = 'UNCHANGED'
            WHERE url = %s
            """
            cursor.execute(
                sql,
                (
                    comment_count,
                    view,
                    created_at,
                    url
                )
            )
            return True
        except Exception as e:
            print(f"[ERROR] comment_count, view ìˆ˜ì • ì—ëŸ¬: {e}")
            traceback.print_exc()
            return None

def log_crawling_metadata(
        conn,
        checked_at: datetime,
        keywords_str: str,
        platform: str,
    ):
    """
    checked_at: datetime ê°ì²´
    """
    try:
        with conn.cursor() as cursor:
            sql = f"""
            INSERT INTO crawling_metadata (
                checked_at,
                keywords_str,
                platform,
                bucket_name
            ) VALUES (
                %s, %s, %s, %s
            )
            """
            cursor.execute(
                sql,
                (
                    checked_at,
                    keywords_str,
                    platform,
                    S3_BUCKET
                )
            )
            conn.commit()
            return True
    except Exception as e:
        print(f"[ERROR] DB ë©”íƒ€ë°ì´í„° ë¡œê¹… ì—ëŸ¬: {e}")
        traceback.print_exc()
        return None
    

def save_s3_bucket_by_parquet(
        checked_at_dt: datetime,
        platform: str,
        data: List[Dict],
    ) -> Optional[bool]:
    """
    checked_at_dt: datetime ê°ì²´

    platform: ì ìš©í•œ í”Œë«í¼
    
    data: [ # í¬ìŠ¤íŒ…
        {
        í”Œë«í¼ "platform"
        ê²€ìƒ‰ í‚¤ì›Œë“œ â€œkeywordâ€
        í¬ìŠ¤íŠ¸ id â€œpost_idâ€
        ì œëª© "title"
        url:  "url"
        ë‚´ìš© "content"
        ì¡°íšŒìˆ˜ "view"
        ì‘ì„±ì¼ì "created_at"
        ì¢‹ì•„ìš” ìˆ˜ "like"
        ì‹«ì–´ìš” ìˆ˜ "dislike"
        ëŒ“ê¸€ìˆ˜ (ì›¹í˜ì´ì§€ ê¸°ë°˜): "comment_count"
        ëŒ“ê¸€: [ {
        # ëŒ“ê¸€ "comment"
        ì‘ì„±ì¼ì: "created_at"
        ë‚´ìš©: "content"
        ì¢‹ì•„ìš” ìˆ˜: "like"
        ì‹«ì–´ìš” ìˆ˜: "dislike"
        },
        {
        ...
        },
        ]
        },
        ...                
    ]

    """
    s3_client = get_s3_client()

    if s3_client is None:
        print("[ERROR] S3 í´ë¼ì´ì–¸íŠ¸ ìƒì„± ì‹¤íŒ¨")
        return None
    
    date = checked_at_dt.date().strftime("%Y-%m-%d")
    hour = str(checked_at_dt.hour)
    minute = str(checked_at_dt.minute)

    # ì½”ë©˜íŠ¸ ë°ì´í„°
    keywords_posts = defaultdict(list)
    keywords_comments = defaultdict(list)

    for post in data:
        # ì½”ë©˜íŠ¸ ì œê±°
        post.pop('id', None)
        post.pop('status', None)
        post.pop('checked_at', None)
        post['platform'] = platform
        try:
            post['like'] = int(post['like'])
        except:
            post['like'] = None
        try:
            post['dislike'] = int(post['dislike']) 
        except:
            post['dislike'] = None
        post['comment_count'] = int(post['comment_count'])
        post['view'] = int(post['view'])
        post_comments = post.pop('comment', [])
        keywords = post.get('keywords', ["no_keyword"])
        post['keywords'] = "|".join(keywords).replace(" ", "_")
        joined_keywords = "-".join((keywords))
        keywords_posts[joined_keywords].append(post)
        # post_idë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì—°ê²°
        for comment in post_comments:
            comment['post_id'] = post['post_id']
            # ì¢‹ì•„ìš”, ì‹«ì–´ìš” ìˆ˜ê°€ ì—†ëŠ” ê²½ìš° Noneìœ¼ë¡œ ì²˜ë¦¬
            try:
                comment['like'] = int(comment['like'])
            except:
                comment['like'] = None            
            try:
                comment['dislike'] = int(comment['dislike'])
            except:
                comment['dislike'] = None
            keywords_comments[joined_keywords].append(comment)
   # ê²Œì‹œë¬¼ ìŠ¤í‚¤ë§ˆ ì •ì˜
    posts_schema = pa.schema([
        ('platform', pa.string()),
        ('title', pa.string()),
        ('post_id', pa.string()),
        ('url', pa.string()),
        ('content', pa.string()),
        ('view', pa.int64()),
        ('created_at', pa.timestamp('s')),  # 'ns' ëŒ€ì‹  's' ì‚¬ìš©
        ('like', pa.int64()),
        ('dislike', pa.int64()),
        ('comment_count', pa.int64()),
        ('keywords', pa.string()),
        ('sentiment', pa.string()),
    ])

    # ëŒ“ê¸€ ìŠ¤í‚¤ë§ˆ ì •ì˜
    comments_schema = pa.schema([
        ('created_at', pa.timestamp('s')),  # 'ns' ëŒ€ì‹  's' ì‚¬ìš©
        ('content', pa.string()),
        ('like', pa.int64()),
        ('dislike', pa.int64()),
        ('post_id', pa.string()),
        ('sentiment', pa.string()),
    ])

    try:
        conn = get_db_connection()
        for keyword, posts in keywords_posts.items():
            # Parquetë¡œ ë³€í™˜
            posts_table = pa.Table.from_pylist(posts, schema=posts_schema)
            comments_table = pa.Table.from_pylist(keywords_comments[keyword], schema=comments_schema)

            # S3 ì—…ë¡œë“œ ê²½ë¡œ ì„¤ì •
            s3_posts_key = f"{date}/{hour}/{minute}/{keyword}/{platform}_posts.parquet"
            s3_comments_key = f"{date}/{hour}/{minute}/{keyword}/{platform}_comments.parquet"

            # ê²Œì‹œë¬¼ ë°ì´í„° ì—…ë¡œë“œ
            with smart_open.open(f"s3://{S3_BUCKET}/{s3_posts_key}", "wb") as s3_file:
                pq.write_table(posts_table, s3_file, compression='snappy')            
            
            # ëŒ“ê¸€ ë°ì´í„° ì—…ë¡œë“œ
            with smart_open.open(f"s3://{S3_BUCKET}/{s3_comments_key}", "wb") as s3_file:
                pq.write_table(comments_table, s3_file, compression='snappy')
            
            print(f"[INFO] S3 ì—…ë¡œë“œ ì™„ë£Œ (í‚¤ì›Œë“œ: {keyword}): {s3_posts_key}, {s3_comments_key}")
            log_crawling_metadata(conn, checked_at_dt, keyword, platform)

        return True
        
    except Exception as e:
        print(f"[ERROR] S3 ì—…ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
        traceback.print_exc()
        return None    

def get_my_ip():
    try:
        # Option 1: Using ipify API
        response = requests.get('https://api.ipify.org')
        print(f"[INFO] AWS NAT Gateway ë³€í™˜ ì´í›„ IP: {response.text.strip()}")
    except:
        try:
            # Option 2: Alternative IP service if ipify fails
            response = requests.get('https://checkip.amazonaws.com')
            print(f"[INFO] AWS NAT Gateway ë³€í™˜ ì´í›„ IP: {response.text.strip()}")
        except:
            return "Failed to get IP address"

openai.api_key = OPENAI_API_KEY

def extract_json_from_response(response_text):
    """
    GPT ì‘ë‹µì—ì„œ JSON ë¶€ë¶„ë§Œ ì¶”ì¶œí•˜ê³  ì •ë¦¬í•˜ëŠ” í•¨ìˆ˜.
    """
    try:
        json_match = json_match_ptrn.search(response_text, re.DOTALL)
        if json_match:
            clean_json = json_match.group(0)
            return json.loads(clean_json)
        else:
            print(f"âš ï¸ JSON íŒ¨í„´ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {response_text}")
            return None
    except json.JSONDecodeError as e:
        print(f"âŒ JSON ë””ì½”ë”© ì‹¤íŒ¨: {e}\nGPT ì‘ë‹µ: {response_text}")
        return None

def analyze_post_with_gpt(post):
    """
    GPT APIë¥¼ ì´ìš©í•´ ê²Œì‹œê¸€ ë° ëŒ“ê¸€ì˜ ê°ì • ë¶„ì„ì„ ìˆ˜í–‰í•˜ê³  ì›ë³¸ ë°ì´í„°ë¥¼ ì—…ë°ì´íŠ¸í•˜ëŠ” í•¨ìˆ˜.
    """
    try:
        title = post.get("title", "ì œëª© ì—†ìŒ")
        content = post.get("content", "ë³¸ë¬¸ ì—†ìŒ")
        comments = post.get("comment", [])

        comment_texts = "\n".join([f"- {c['content']}" for c in comments])

        prompt = f"""
        ì•„ë˜ ê²Œì‹œê¸€ ë‚´ìš©ì„ ë¶„ì„í•˜ì—¬ ê°ì • ë¶„ì„(sentiment analysis)ì„ ìˆ˜í–‰í•˜ì„¸ìš”.

        ì œëª©: {title}
        ë³¸ë¬¸: {content}
        ëŒ“ê¸€:
        {comment_texts}

        ë¶„ì„í•  ë‚´ìš©:
        1. **ê²Œì‹œê¸€ ê°ì • ë¶„ì„**: ê²Œì‹œê¸€ì˜ ê°ì •ì„ titleì™€ contentë¥¼ ì´ìš©í•´ì„œ 'ë²¤ì¸ 'ë¼ëŠ” ë‹¨ì–´ë¥¼ ê¸°ì¤€ìœ¼ë¡œ 'ê¸ì •/ë¶€ì •/ì¤‘ë¦½' ì¤‘ í•˜ë‚˜ë¡œ íŒë‹¨í•˜ì„¸ìš”.
        2. **ëŒ“ê¸€ ê°ì • ë¶„ì„**: ê° ëŒ“ê¸€ì˜ ê°ì •ì„ title, content, comment_textsì™€ ê²Œì‹œê¸€ ê°ì •ì„ ì°¸ê³ í•˜ì—¬ 'ë²¤ì¸ 'ë¼ëŠ” ë‹¨ì–´ë¥¼ ê¸°ì¤€ìœ¼ë¡œ 'ê¸ì •/ë¶€ì •/ì¤‘ë¦½'ìœ¼ë¡œ ë¶„ë¥˜í•˜ì„¸ìš”.

        **ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”.**
        JSON í˜•ì‹:
        {{
            "ê²Œì‹œê¸€ ê°ì •": "positive/negative/neutral",
            "comment_sentiments": [
                {{"ë‚´ìš©": "ëŒ“ê¸€1 ë‚´ìš©", "ê°ì •": "positive/negative/neutral"}},
                {{"ë‚´ìš©": "ëŒ“ê¸€2 ë‚´ìš©", "ê°ì •": "positive/negative/neutral"}}
            ]
        }}
        """

        response = openai.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "system", "content": "ë„ˆëŠ” JSON ì‘ë‹µì„ ì œê³µí•˜ëŠ” AIì•¼."},
                      {"role": "user", "content": prompt}],
            temperature=0.7,
        )

        gpt_output = response.choices[0].message.content
        print(f"ğŸ“Œ GPT ì‘ë‹µ ë‚´ìš©: {gpt_output}")

        if not gpt_output:
            raise ValueError("GPT ì‘ë‹µì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")

        analysis_result = extract_json_from_response(gpt_output)
        if not analysis_result:
            print("âŒ ê°ì • ë¶„ì„ ì‹¤íŒ¨: JSON ì‘ë‹µì„ íŒŒì‹±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return post

        # ê²Œì‹œê¸€ ê°ì • ë¶„ì„ ê²°ê³¼ ì¶”ê°€
        post["sentiment"] = analysis_result.get("ê²Œì‹œê¸€ ê°ì •", "neutral")

        # ëŒ“ê¸€ ê°ì • ë¶„ì„ ê²°ê³¼ ì¶”ê°€
        if "comment_sentiments" in analysis_result:
            for com, gpts in zip(post["comment"], analysis_result["comment_sentiments"]):
                com["sentiment"] = gpts["ê°ì •"]

        return post

    except Exception as e:
        print(f"âŒ GPT API í˜¸ì¶œ ì˜¤ë¥˜: {e}")
        return post  # ì˜¤ë¥˜ ë°œìƒ ì‹œ ì›ë³¸ ë°ì´í„° ë°˜í™˜


if __name__ == "__main__":
    db_conn = get_db_connection()


